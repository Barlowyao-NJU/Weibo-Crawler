{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139258013983001\n",
      "https://m.weibo.cn/comments/hotflow?id=4540058705068663&mid=4540058705068663&max_id=139258013983001&max_id_type=0\n",
      "138158513817069\n",
      "https://m.weibo.cn/comments/hotflow?id=4540058705068663&mid=4540058705068663&max_id=138158513817069&max_id_type=0\n",
      "138158502432903\n",
      "https://m.weibo.cn/comments/hotflow?id=4540058705068663&mid=4540058705068663&max_id=138158502432903&max_id_type=0\n",
      "138158502359332\n",
      "https://m.weibo.cn/comments/hotflow?id=4540058705068663&mid=4540058705068663&max_id=138158502359332&max_id_type=0\n",
      "138158502121390\n",
      "https://m.weibo.cn/comments/hotflow?id=4540058705068663&mid=4540058705068663&max_id=138158502121390&max_id_type=0\n",
      "169811922181\n",
      "https://m.weibo.cn/comments/hotflow?id=4540058705068663&mid=4540058705068663&max_id=169811922181&max_id_type=0\n",
      "169793100981\n",
      "https://m.weibo.cn/comments/hotflow?id=4540058705068663&mid=4540058705068663&max_id=169793100981&max_id_type=0\n",
      "now to next account\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import xlrd\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from config import headers,Cookie\n",
    "\n",
    "initial_url='https://m.weibo.cn/comments/hotflow?id={}&mid={}&max_id_type=0'\n",
    "next_url='https://m.weibo.cn/comments/hotflow?id={}&mid={}&max_id={}&max_id_type=0'\n",
    "continue_url = initial_url\n",
    "max_id_type=0\n",
    "count=0\n",
    "data_Dict = {'data':[]} \n",
    "fileName=''\n",
    "\n",
    "def Get_CHN(text):\n",
    "    dr = re.compile(r'<[^>]+>',re.S)\n",
    "    dd = dr.sub('',text)\n",
    "    data_Dict['data'].append(dd)\n",
    "    write_to_excel(data_Dict)\n",
    "\n",
    "def read_excel(path): #读取excel文档中的数据，返回一个DataFrame\n",
    "    data = pd.read_excel(str(path),sheet_name=0)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def url_generator(_id,_mid): #生成初始网页URL和下一个网URL模板\n",
    "    global initial_url,next_url\n",
    "    initial_url='https://m.weibo.cn/comments/hotflow?id={}&mid={}&max_id_type=0' #一个循环后重置URL模板\n",
    "    next_url='https://m.weibo.cn/comments/hotflow?id={}&mid={}&max_id={}&max_id_type={}'\n",
    "    continue_url = initial_url\n",
    "    \n",
    "    initial_url = initial_url.format(str(_id),str(_mid))\n",
    "    next_url=next_url.format(str(_id),str(_mid),\"{}\",\"{}\")\n",
    "\n",
    "def get_page(url): #请求页面\n",
    "    try:\n",
    "        requests.DEFAULT_RETRIES = 5  # 增加重试连接次数\n",
    "        s = requests.session()\n",
    "        s.keep_alive = False  # 关闭多余连接\n",
    "        r = requests.get(url, headers=headers,cookies=Cookie)\n",
    "        if r.status_code == 200:\n",
    "            return r.json()\n",
    "        else:\n",
    "            if r.status_code == 200:\n",
    "                return r.json()\n",
    "    except requests.ConnectionError as e:\n",
    "        print('error', e.args)\n",
    "\n",
    "def get_data(data): #解析页面返回的json数据\n",
    "    if data['ok']==1:\n",
    "        global count\n",
    "        if count>=15:\n",
    "            max_id_type=1\n",
    "        else:\n",
    "            max_id_type=0\n",
    "            \n",
    "        max_id = data.get(\"data\").get(\"max_id\")\n",
    "        if max_id != 0:\n",
    "            comments = data.get('data').get('data')\n",
    "            for arg in comments:\n",
    "                Get_CHN(arg.get('text'))\n",
    "            count+=1\n",
    "            print(max_id)\n",
    "            \n",
    "\n",
    "            global next_url # 通过max_id生成下一个页面的url\n",
    "            continue_url = next_url.format(str(max_id),max_id_type)\n",
    "            print(continue_url)\n",
    "\n",
    "            time.sleep(5)\n",
    "            datafornextpage=get_page(continue_url) #访问下一个页面\n",
    "            get_data(datafornextpage) #函数内递归调用\n",
    "        else:\n",
    "            comments = data.get('data').get('data')\n",
    "            for arg in comments:\n",
    "                Get_CHN(arg.get('text'))\n",
    "    else:\n",
    "        print('error')\n",
    "        \n",
    "\n",
    "def write_to_excel(content):\n",
    "    pdData = pd.DataFrame(data_Dict)\n",
    "    pdData.to_excel(\"{0}.xlsx\".format(fileName),encoding='utf_8_sig')\n",
    "    \n",
    "if __name__ == \"__main__\":   \n",
    "    excel_data = read_excel(\"#乐山五通桥市民因异味自发撤离#.xlsx\")\n",
    "    for count in range(0,excel_data['URL'].count()):\n",
    "        global fileName\n",
    "        fileName = str(excel_data['source'][count])\n",
    "        url_generator(excel_data['id'][count],excel_data['mid'][count])\n",
    "        jsondata = get_page(initial_url)\n",
    "        get_data(jsondata)\n",
    "        data_Dict = {'data':[]} \n",
    "        print(\"now to next account\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
